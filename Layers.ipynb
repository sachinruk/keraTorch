{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "> All the basic layers used keratorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import torch.nn as nn\n",
    "from fastai.vision import *\n",
    "\n",
    "from keraTorch.activations import *\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class __inputDimError__(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dense:\n",
    "    def __init__(self, units, input_dim=None, activation=None, \n",
    "                 use_bias=True, kernel_regularizer=None, bias_regularizer=None, \n",
    "                 activity_regularizer=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.activation = get_activation(activation) if activation else None\n",
    "        if input_dim:\n",
    "            self.linear = nn.Linear(input_dim, units, bias=use_bias)\n",
    "        else:\n",
    "            self.linear = partial(nn.Linear, out_features=units, bias=use_bias)\n",
    "        # TODO: implement regularizers\n",
    "        \n",
    "    def get_layer(self, input_dim=None):\n",
    "        if input_dim is None and self.input_dim is None:\n",
    "            __inputDimError__(\"Need to specify number of input dimensions in first layer\")\n",
    "        elif input_dim:\n",
    "            self.linear = self.linear(in_features=input_dim)\n",
    "        # else self.linear is already is assigned\n",
    "        \n",
    "        output_dim = self.linear.out_features\n",
    "        layers = [layer for layer in [self.linear, self.activation] if layer]\n",
    "        \n",
    "        return {'output_dim': output_dim, 'layers': layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': 3,\n",
       " 'layers': [Linear(in_features=5, out_features=3, bias=True), Mish()]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "Dense(3, 5, activation='mish').get_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted Activations.ipynb.\n",
      "Converted Layers.ipynb.\n",
      "Converted Model.ipynb.\n",
      "Converted data.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AUTOGENERATED! DO NOT EDIT! File to edit: Layers.ipynb (unless otherwise specified).\r\n",
      "\r\n",
      "__all__ = ['__inputDimError__', 'Dense']\r\n",
      "\r\n",
      "# Cell\r\n",
      "import torch.nn as nn\r\n",
      "from fastai.vision import *\r\n",
      "\r\n",
      "from .activations import *\r\n",
      "from functools import partial\r\n",
      "\r\n",
      "# Cell\r\n",
      "class __inputDimError__(Exception):\r\n",
      "    pass\r\n",
      "\r\n",
      "# Cell\r\n",
      "class Dense:\r\n",
      "    def __init__(self, units, input_dim=None, activation=None,\r\n",
      "                 use_bias=True, kernel_regularizer=None, bias_regularizer=None,\r\n",
      "                 activity_regularizer=None):\r\n",
      "        super().__init__()\r\n",
      "\r\n",
      "        self.input_dim = input_dim\r\n",
      "        self.activation = get_activation(activation) if activation else None\r\n",
      "        if input_dim:\r\n",
      "            self.linear = nn.Linear(input_dim, units, bias=use_bias)\r\n",
      "        else:\r\n",
      "            self.linear = partial(nn.Linear, out_features=units, bias=use_bias)\r\n",
      "        # TODO: implement regularizers\r\n",
      "\r\n",
      "    def get_layer(self, input_dim=None):\r\n",
      "        if input_dim is None and self.input_dim is None:\r\n",
      "            __inputDimError__(\"Need to specify number of input dimensions in first layer\")\r\n",
      "        elif input_dim:\r\n",
      "            self.linear = self.linear(input_dim=input_dim)\r\n",
      "        # else self.linear is already is assigned\r\n",
      "\r\n",
      "        output_dim = self.linear.out_features\r\n",
      "        layers = [layer for layer in [self.linear, self.activation] if layer]\r\n",
      "\r\n",
      "        return {'output_dim': output_dim, 'layers': layers}"
     ]
    }
   ],
   "source": [
    "!cat keraTorch/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
