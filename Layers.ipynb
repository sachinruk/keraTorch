{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "> All the basic layers used keratorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from fastai.vision import *\n",
    "from fastai import layers\n",
    "\n",
    "from keraTorch.activations import *\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class __inputDimError__(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_shape=None):\n",
    "#         breakpoint()\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def __set_io_shape__(self, input_shape):\n",
    "        if input_shape is None and self.input_shape is None:\n",
    "            __inputDimError__(\"Need to specify input shape in first layer\")\n",
    "        elif input_shape:\n",
    "            self.input_shape = input_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense\n",
    "Linear layer that takes in `input_dim` and converts it to `units` number of dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Dense:\n",
    "    def __init__(self, units, input_dim=None, activation=None, \n",
    "                 use_bias=True, kernel_regularizer=None, bias_regularizer=None, \n",
    "                 activity_regularizer=None):\n",
    "        \"\"\"\n",
    "        Linear layer that takes in `input_dim` and converts it to `units` number of dimensions.\n",
    "        parameters:\n",
    "        - units: output dimension.\n",
    "        - input_dim: input dimension.\n",
    "        - activation (optional): non-linear activation.\n",
    "        - use_bias (optional): To include bias layer or not (default: True)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.activation = get_activation(activation) if activation else None\n",
    "        if input_dim:\n",
    "            self.layer = nn.Linear(input_dim, units, bias=use_bias)\n",
    "        else:\n",
    "            self.layer = partial(nn.Linear, out_features=units, bias=use_bias)\n",
    "        # TODO: implement regularizers\n",
    "        \n",
    "    def get_layer(self, input_dim=None):\n",
    "        if input_dim is None and self.input_dim is None:\n",
    "            __inputDimError__(\"Need to specify number of input dimensions in first layer\")\n",
    "        elif input_dim:\n",
    "            self.input_dim = input_dim\n",
    "            self.layer = self.layer(in_features=input_dim)\n",
    "        # else self.layer is already is assigned\n",
    "        \n",
    "        self.output_dim = self.layer.out_features\n",
    "        layers = [layer for layer in [self.layer, self.activation] if layer]\n",
    "        \n",
    "        return {'output_dim': self.output_dim, 'layers': layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': 3,\n",
       " 'layers': [Linear(in_features=5, out_features=3, bias=True), Mish()]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hide\n",
    "Dense(3, 5, activation='mish').get_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': 3,\n",
       " 'layers': [Linear(in_features=5, out_features=3, bias=True), Mish()]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dense(3, activation='mish').get_layer(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Conv2D:\n",
    "    def __init__(self, filters:int, kernel_size:int=3, strides:int=1, padding:int=None, \n",
    "                 activation:str=None, use_bias:bool=True, input_shape:tuple=None):\n",
    "        \"\"\"\n",
    "        Apply convolution on image using kernel filters.\n",
    "        parameters:\n",
    "        - filters: number of kernel filters\n",
    "        - kernel_size: the width of the (square) kernel\n",
    "        - strides: number of pixels to skip when sliding kernel (default 1)\n",
    "        - padding: number of pixels to pad incoming image ` defaults to `ks//2`\n",
    "        - activation: non-linearity\n",
    "        - use_bias: bias\n",
    "        - input_shape: incoming image shape of (#Channels, width, height)\n",
    "        \"\"\"\n",
    "        self.input_shape = input_shape\n",
    "        if input_shape:\n",
    "            ni = input_shape[0]\n",
    "            self.layer = conv2d(ni, filters, kernel_size, strides, padding, use_bias)\n",
    "        else:\n",
    "            self.layer = partial(conv2d, nf=filters, ks=kernel_size, \n",
    "                                 stride=strides, padding=padding, bias=use_bias)\n",
    "        self.activation = get_activation(activation) if activation else None\n",
    "        \n",
    "    def get_layer(self, input_shape=None):\n",
    "        \n",
    "        ni = self.input_shape[0]\n",
    "        self.layer = self.layer(ni=ni)\n",
    "        # else self.input_shape is already is assigned\n",
    "\n",
    "        dummy_x = torch.zeros(self.input_shape).unsqueeze(0)\n",
    "        self.output_shape = self.layer(dummy_x).shape[1:]\n",
    "        layers = [layer for layer in [self.layer, self.activation] if layer]\n",
    "        \n",
    "        return {'output_dim': self.output_shape, 'layers': layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': torch.Size([5, 10, 10]),\n",
       " 'layers': [Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  ReLU(inplace=True)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2D(5, activation='Relu', input_shape=(1, 10, 10)).get_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': torch.Size([5, 10, 10]),\n",
       " 'layers': [Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
       "  ReLU(inplace=True)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conv2D(5, activation='Relu').get_layer((1, 10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Flatten:\n",
    "    def __init__(self, input_shape=None):\n",
    "        self.layer = layers.Flatten()\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "    def get_layer(self, input_shape=None):\n",
    "        if input_shape is None and self.input_shape is None:\n",
    "            __inputDimError__(\"Need to specify input shape in first layer\")\n",
    "        elif input_shape:\n",
    "            self.input_shape = input_shape\n",
    "        # else self.input_shape is already is assigned\n",
    "\n",
    "        self.output_dim = np.prod(self.input_shape)\n",
    "        layers = [self.layer]\n",
    "        \n",
    "        return {'output_dim': self.output_dim, 'layers': layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': 15, 'layers': [Flatten()]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = Flatten((5, 3))\n",
    "flatten.get_layer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Activation:\n",
    "    def __init__(self, activation, input_shape=None):\n",
    "        self.layer = get_activation(activation)\n",
    "        self.input_shape = input_shape\n",
    "        self.output_dim = input_shape\n",
    "        \n",
    "    def get_layer(self, input_shape=None):\n",
    "        if input_shape is None and self.input_shape is None:\n",
    "            __inputDimError__(\"Need to specify input shape in first layer\")\n",
    "        elif input_shape:\n",
    "            self.input_shape = input_shape\n",
    "            self.output_dim = input_shape\n",
    "        # else self.input_shape is already is assigned\n",
    "\n",
    "        layers = [self.layer]\n",
    "        \n",
    "        return {'output_dim': self.output_dim, 'layers': layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dim': None, 'layers': [Softmax(dim=-1)]}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Activation('softmax').get_layer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Activations.ipynb.\n",
      "Converted Layers.ipynb.\n",
      "Converted Model.ipynb.\n",
      "Converted data.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted losses.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# AUTOGENERATED! DO NOT EDIT! File to edit: Layers.ipynb (unless otherwise specified).\r\n",
      "\r\n",
      "__all__ = ['__inputDimError__', 'Dense', 'Conv2D', 'Flatten', 'Activation']\r\n",
      "\r\n",
      "# Cell\r\n",
      "import numpy as np\r\n",
      "import torch.nn as nn\r\n",
      "from fastai.vision import *\r\n",
      "from fastai import layers\r\n",
      "\r\n",
      "from .activations import *\r\n",
      "from functools import partial\r\n",
      "\r\n",
      "# Cell\r\n",
      "class __inputDimError__(Exception):\r\n",
      "    pass\r\n",
      "\r\n",
      "# Cell\r\n",
      "class Dense:\r\n",
      "    def __init__(self, units, input_dim=None, activation=None,\r\n",
      "                 use_bias=True, kernel_regularizer=None, bias_regularizer=None,\r\n",
      "                 activity_regularizer=None):\r\n",
      "        \"\"\"\r\n",
      "        Linear layer that takes in `input_dim` and converts it to `units` number of dimensions.\r\n",
      "        parameters:\r\n",
      "        - units: output dimension.\r\n",
      "        - input_dim: input dimension.\r\n",
      "        - activation (optional): non-linear activation.\r\n",
      "        - use_bias (optional): To include bias layer or not (default: True)\r\n",
      "        \"\"\"\r\n",
      "        super().__init__()\r\n",
      "\r\n",
      "        self.input_dim = input_dim\r\n",
      "        self.activation = get_activation(activation) if activation else None\r\n",
      "        if input_dim:\r\n",
      "            self.layer = nn.Linear(input_dim, units, bias=use_bias)\r\n",
      "        else:\r\n",
      "            self.layer = partial(nn.Linear, out_features=units, bias=use_bias)\r\n",
      "        # TODO: implement regularizers\r\n",
      "\r\n",
      "    def get_layer(self, input_dim=None):\r\n",
      "        if input_dim is None and self.input_dim is None:\r\n",
      "            __inputDimError__(\"Need to specify number of input dimensions in first layer\")\r\n",
      "        elif input_dim:\r\n",
      "            self.input_dim = input_dim\r\n",
      "            self.layer = self.layer(in_features=input_dim)\r\n",
      "        # else self.layer is already is assigned\r\n",
      "\r\n",
      "        self.output_dim = self.layer.out_features\r\n",
      "        layers = [layer for layer in [self.layer, self.activation] if layer]\r\n",
      "\r\n",
      "        return {'output_dim': self.output_dim, 'layers': layers}\r\n",
      "\r\n",
      "# Cell\r\n",
      "class Conv2D:\r\n",
      "    def __init__(self, filters:int, kernel_size:int=3, strides:int=1, padding:int=None,\r\n",
      "                 activation:str=None, use_bias:bool=True, input_shape:tuple=None):\r\n",
      "        \"\"\"\r\n",
      "        Apply convolution on image using kernel filters.\r\n",
      "        parameters:\r\n",
      "        - filters: number of kernel filters\r\n",
      "        - kernel_size: the width of the (square) kernel\r\n",
      "        - strides: number of pixels to skip when sliding kernel (default 1)\r\n",
      "        - padding: number of pixels to pad incoming image ` defaults to `ks//2`\r\n",
      "        - activation: non-linearity\r\n",
      "        - use_bias: bias\r\n",
      "        - input_shape: incoming image shape of (#Channels, width, height)\r\n",
      "        \"\"\"\r\n",
      "        self.input_shape = input_shape\r\n",
      "        if input_shape:\r\n",
      "            ni = input_shape[0]\r\n",
      "            self.layer = conv2d(ni, filters, kernel_size, strides, padding, use_bias)\r\n",
      "        else:\r\n",
      "            self.layer = partial(conv2d, nf=filters, ks=kernel_size,\r\n",
      "                                 stride=strides, padding=padding, bias=use_bias)\r\n",
      "        self.activation = get_activation(activation) if activation else None\r\n",
      "\r\n",
      "    def get_layer(self, input_shape=None):\r\n",
      "\r\n",
      "        ni = self.input_shape[0]\r\n",
      "        self.layer = self.layer(ni=ni)\r\n",
      "        # else self.input_shape is already is assigned\r\n",
      "\r\n",
      "        dummy_x = torch.zeros(self.input_shape).unsqueeze(0)\r\n",
      "        self.output_shape = self.layer(dummy_x).shape[1:]\r\n",
      "        layers = [layer for layer in [self.layer, self.activation] if layer]\r\n",
      "\r\n",
      "        return {'output_dim': self.output_shape, 'layers': layers}\r\n",
      "\r\n",
      "# Cell\r\n",
      "class Flatten:\r\n",
      "    def __init__(self, input_shape=None):\r\n",
      "        self.layer = layers.Flatten()\r\n",
      "        self.input_shape = input_shape\r\n",
      "\r\n",
      "    def get_layer(self, input_shape=None):\r\n",
      "        if input_shape is None and self.input_shape is None:\r\n",
      "            __inputDimError__(\"Need to specify input shape in first layer\")\r\n",
      "        elif input_shape:\r\n",
      "            self.input_shape = input_shape\r\n",
      "        # else self.input_shape is already is assigned\r\n",
      "\r\n",
      "        self.output_dim = np.prod(self.input_shape)\r\n",
      "        layers = [self.layer]\r\n",
      "\r\n",
      "        return {'output_dim': self.output_dim, 'layers': layers}\r\n",
      "\r\n",
      "# Cell\r\n",
      "class Activation:\r\n",
      "    def __init__(self, activation, input_shape=None):\r\n",
      "        self.layer = get_activation(activation)\r\n",
      "        self.input_shape = input_shape\r\n",
      "        self.output_dim = input_shape\r\n",
      "\r\n",
      "    def get_layer(self, input_shape=None):\r\n",
      "        if input_shape is None and self.input_shape is None:\r\n",
      "            __inputDimError__(\"Need to specify input shape in first layer\")\r\n",
      "        elif input_shape:\r\n",
      "            self.input_shape = input_shape\r\n",
      "            self.output_dim = input_shape\r\n",
      "        # else self.input_shape is already is assigned\r\n",
      "\r\n",
      "        layers = [self.layer]\r\n",
      "\r\n",
      "        return {'output_dim': self.output_dim, 'layers': layers}"
     ]
    }
   ],
   "source": [
    "!cat keraTorch/layers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
